{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4da9e2d-daed-4a16-bfff-fb5f087d4df2",
   "metadata": {},
   "source": [
    "# Simulation Based Inference For NeuroScience: The BOLD signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d3990e-103d-4b2a-9a10-581cb6e9a6f3",
   "metadata": {},
   "source": [
    "## Table Of Content:\n",
    "* [Setup](#set-up)\n",
    "* [Train a Density Estimator](#density-estimator)\n",
    "* [Creating X](#creating-X)\n",
    "* [Loading Simulation Results](#simulation)\n",
    "* [Training the Neural Network](#training)\n",
    "* [Validating Results & Saving Plots](#validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6330678-2999-4b88-8d0b-ea93e8c14fd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup<a class=\"anchor\" id=\"set-up\"></a>\n",
    "\n",
    "First import the needed libraries (and set current working directory if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e728d79-1e16-4f04-b721-02b4f97844fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, before starting, change the current working directory by uncommenting and inserting the right path:\n",
    "import os\n",
    "# os.chdir(\"/home/coder/projects/lorenz_sbi\")\n",
    "\n",
    "# General libraries:\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import argparse \n",
    "import torch \n",
    "\n",
    "from sbi.inference import SNPE, SNLE, SNRE\n",
    "\n",
    "# For plotting:\n",
    "from sbi.analysis import pairplot, conditional_pairplot\n",
    "from utils import marginal_correlation\n",
    "\n",
    "# Functions:\n",
    "from train import train\n",
    "\n",
    "# Get the path of the current working directory: \n",
    "cwd_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e07450",
   "metadata": {},
   "source": [
    "## Train a density estimator<a class=\"anchor\" id=\"density-estimator\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75d21ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a density estimator.\n",
    "# If desired, change the number of threads to a higher number (by default it's 1).\n",
    "parser = argparse.ArgumentParser(description=\"Train a density estimator.\")\n",
    "parser.add_argument(\"--data\", type=str, default=cwd_path + \"/data/X_train_01.npy\", help=\"Path to the data file.\")\n",
    "parser.add_argument(\"--method\", type=str, default=\"SNPE\", help=\"Inference method.\")\n",
    "parser.add_argument(\"--density_estimator\", type=str, default=\"maf\", help=\"Density estimator.\")\n",
    "parser.add_argument(\"--num_threads\", type=int, default=1, help=\"Number of threads.\")\n",
    "parser.add_argument(\"--device\", type=str, default=\"cpu\", help=\"Device.\")\n",
    "\n",
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f74a4a",
   "metadata": {},
   "source": [
    "## Creating X<a class=\"anchor\" id=\"creating-X\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bed2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in beta files (input to our NN).\n",
    "# First read in 1 file:\n",
    "betas = np.load(cwd_path + \"/data/Betas_01.npy\")\n",
    "\n",
    "# Append the rest of the beta batches to this file:\n",
    "for number in range(2, 11):\n",
    "    #print(number)\n",
    "    if number <= 9:\n",
    "        beta_files = np.load(cwd_path + \"/data/Betas_0\" + str(number) + \".npy\")\n",
    "        betas = np.concatenate((betas, beta_files))\n",
    "    else:\n",
    "        beta_files = np.load(cwd_path + \"/data/Betas_10.npy\")\n",
    "        betas = np.concatenate((betas, beta_files))\n",
    "\n",
    "# Read in our parameters.\n",
    "total_combinations = np.load(cwd_path + \"/data/total_combinations.npy\")\n",
    "\n",
    "\n",
    "# Check whether the number of rows match between our parameters and beta values.\n",
    "print(\"Does the length match between the parameters and the beta value (returns True if this is true)?\", len(total_combinations) == len(betas))\n",
    "\n",
    "# Concatenate both together:\n",
    "X = np.concatenate((total_combinations, betas), axis = 1)\n",
    "\n",
    "print(\"The shape of X is: \", X.shape)\n",
    "print(\"The first row/simulation in X is: \", \"\\n\", X[0])\n",
    "\n",
    "np.save(cwd_path + \"/data/X.npy\", X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf2a7b5-6c6e-4478-b8f8-007091d4289d",
   "metadata": {},
   "source": [
    "## Loading Simulation Results<a class=\"anchor\" id=\"simulation\"></a>\n",
    "\n",
    "As shuffle is not deterministic (till need to include a seed as np.random.seed() does not work as intended), we will save our X_train and X_test instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa87b568-4118-493c-b7e9-cba3db39b7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "[5.91164975 5.91920401 5.96471115 0.13882868 0.11480275 0.1577574\n",
      " 0.11480275 0.10333426 0.11946977 0.1577574  0.11946977 0.19903269\n",
      " 1.         0.95849652 0.94904747 0.95849652 1.         0.83305496\n",
      " 0.94904747 0.83305496 1.         8.50382875 5.87806224 7.00083841]\n",
      "[[5.91164975 5.91920401 5.96471115 0.13882868 0.11480275 0.1577574\n",
      "  0.11480275 0.10333426 0.11946977 0.1577574  0.11946977 0.19903269\n",
      "  1.         0.95849652 0.94904747 0.95849652 1.         0.83305496\n",
      "  0.94904747 0.83305496 1.         8.50382875 5.87806224 7.00083841]]\n"
     ]
    }
   ],
   "source": [
    "X = np.load(cwd_path + \"/data/X.npy\")\n",
    "print(X.shape)\n",
    "print(X[0])\n",
    "\n",
    "# # Split this matrix into train and test data.\n",
    "\n",
    "# # Shuffle the X to make sure different combinations end up in the train and test sets.\n",
    "# np.random.shuffle(X)\n",
    "\n",
    "# # Take 10% of the data for test (there are 11520 simulations in X, 10% is 1152 which goes to test, the rest goes to X_train).\n",
    "# X_train = X[:10368, :]\n",
    "# X_test = X[10368:, :]\n",
    "\n",
    "# # Save this train and test set.\n",
    "# np.save(cwd_path + \"/data/X_train_01.npy\", X_train)\n",
    "# np.save(cwd_path + \"/data/X_test_01.npy\", X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4b9a8d-93ab-43c0-bdfc-50aca85e2187",
   "metadata": {},
   "source": [
    "## Training the Neural Network <a class=\"anchor\" id=\"training\"></a>\n",
    "\n",
    "There is a pretrained posterior present in the models map. If you want to retrain it, uncomment the block of code below before running it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4407948a-0310-474d-aa31-30de5523615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_01 = np.load(args.data, allow_pickle=True)\n",
    "X_test_01 = np.load(cwd_path + \"/data/X_test_01.npy\")\n",
    "\n",
    "# # Establish how many simulations are in the data \n",
    "# num_simulations = X_train_01.shape[0]\n",
    "\n",
    "# # Seperate simulation parameters and summary statistics\n",
    "# params = X_train_01[:, -4:]\n",
    "# stats  = X_train_01[:, :-4]\n",
    "\n",
    "# # When working with Torch, the matrix has to be parsed to a Torch object \n",
    "# theta = torch.from_numpy(params).float()\n",
    "# x = torch.from_numpy(stats).float()\n",
    "\n",
    "# # Train the posterior with all the arguments needed \n",
    "# posterior = train(num_simulations,\n",
    "#                     x,\n",
    "#                     theta,\n",
    "#                     num_threads         = args.num_threads,\n",
    "#                     method              = args.method,\n",
    "#                     device              = args.device,\n",
    "#                     density_estimator   = args.density_estimator\n",
    "#                     )\n",
    "\n",
    "# # Save posterior (intermediate result).\n",
    "# torch.save(posterior, cwd_path + \"/models/posterior_01.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45087be-d8dc-4520-9ce7-5035813a611b",
   "metadata": {},
   "source": [
    "## Validating Results & Saving Plots <a class=\"anchor\" id=\"validation\"></a>\n",
    "\n",
    "*Warning: when this code is run 1152 pairplots and correlation plots will be saved in the png-map! (for every simulation 2 plots and we have 1152 simulations as test data).*\n",
    "\n",
    "To-do: change the for-loop to display the plot in a different way (don't use pairplots) & incorporate the error between the actual value and the inferred parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7d90fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Iterate through all simulations, using the beta values see how well the original parameters can be inferred (all the plots are saved).\n",
    "\n",
    "# for number in range(0, 1153):\n",
    "#     obs_x = X_test_01[number, -4:] # Get default stats\n",
    "#     obs_theta = X_test_01[number, :-4] # Get default params\n",
    "\n",
    "#     posterior = torch.load(cwd_path + \"/models/posterior_01.pt\") # Load posterior\n",
    "\n",
    "#     num_samples = 100000\n",
    "\n",
    "#     posterior.set_default_x(obs_x)\n",
    "#     posterior_samples = posterior.sample((num_samples,))\n",
    "\n",
    "#     # Plotting\n",
    "#     plt.figure()\n",
    "#     fig, ax = pairplot(samples=posterior_samples, labels=[r\"$NU_1$\", r\"$NU_2$\", r\"$NU_3$\", r\"$NU_4$\", r\"$NU_5$\", r\"$NU_6$\", \n",
    "#                        r\"$NU_7$\", r\"$NU_8$\"], figsize=(20, 20))\n",
    "\n",
    "#     plt.savefig(cwd_path + \"/plot_images/pairplot_01_\" + str(number) + \".png\") # Save figure\n",
    "#     plt.close()\n",
    "\n",
    "#     plt.figure()\n",
    "#     fig, ax = marginal_correlation(samples=posterior_samples, labels=[r\"$NU_1$\", r\"$NU_2$\", r\"$NU_3$\", r\"$NU_4$\", r\"$NU_5$\", r\"$NU_6$\", \n",
    "#                                    r\"$NU_7$\", r\"$NU_8$\"], figsize=(10, 10))\n",
    "\n",
    "#     plt.savefig(cwd_path + \"/plot_images/marginal_correlation_01_\" + str(number) + \".png\") # Save figure\n",
    "#     plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
